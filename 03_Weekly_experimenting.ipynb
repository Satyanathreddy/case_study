{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the model experimentation and finalization. It covers EDA, outlier treatment, transformation, training, model evaluation and comparison across models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "\n",
    "# standard third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# impute missing values\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import KNNImputer, IterativeImputer, SimpleImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from category_encoders import TargetEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append(r\"D:\\CodeTemplate-Regrassion\\regression-py\\regression-py\\src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', message=\"pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\", \n",
    "                        category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', message=\"pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\",\n",
    "                        category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard code-template imports\n",
    "from ta_lib.core.api import (\n",
    "    create_context, get_dataframe, get_feature_names_from_column_transformer, string_cleaning,\n",
    "    get_package_path, display_as_tabs, save_pipeline, load_pipeline, initialize_environment,\n",
    "    load_dataset, save_dataset, DEFAULT_ARTIFACTS_PATH\n",
    ")\n",
    "\n",
    "import ta_lib.eda.api as eda\n",
    "from xgboost import XGBRegressor\n",
    "from ta_lib.regression.api import SKLStatsmodelOLS\n",
    "from ta_lib.regression.api import RegressionComparison, RegressionReport\n",
    "import ta_lib.reports.api as reports\n",
    "from ta_lib.data_processing.api import Outlier\n",
    "\n",
    "initialize_environment(debug=False, hide_warnings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_folder = DEFAULT_ARTIFACTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = op.join('conf', 'config.yml')\n",
    "context = create_context(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Feature Engineering\n",
    "\n",
    "The focus here is the `Pipeline` and not the model. Though the model would inform the pipeline that is needed to train the model, our focus is to set it up in such a way that it can be saved/loaded, tweaked for different model choices and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Read the Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2080, 13) (2080, 1)\n",
      "(634, 13) (634, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X = load_dataset(context, 'train/Data/features')\n",
    "train_y = load_dataset(context, 'train/Data/target')\n",
    "print(train_X.shape, train_y.shape)\n",
    "\n",
    "test_X = load_dataset(context, 'test/Data/features')\n",
    "test_y = load_dataset(context, 'test/Data/target')\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Feature Engineering Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev NOTES**\n",
    "\n",
    "For Feature Engineering and Model Building sklearn.pipeline.Pipeline are leveraged because of the following advantages\n",
    "<details>\n",
    "    \n",
    "1. It helps in automating workflows and are easier to read and comprehend.\n",
    "2. Right Sequence can be ensured and (for example always encodes before imputing)\n",
    "3. Reproducibility is very convenient with pipelines\n",
    "4. Pipelines help you prevent data leakage in your test data\n",
    "5. Code is near implementation ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Steps in the Feature Transformation are as follows\n",
    " - Outlier Treatment\n",
    " - Encoding of Categorical Columns\n",
    " - Missing Values Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting different types of columns for transformations\n",
    "cat_columns = train_X.select_dtypes('object').columns\n",
    "num_columns = train_X.select_dtypes('number').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Handling\n",
    "- A Custom Transformer is used to handle outliers. It is not included as part of the pipeline as outliers handling are optional for test data\n",
    "- An option to either drop or cap the outliers can be passed during the transform call\n",
    "- If we want to treat outliers for some columns them we can pass cols argument to the Transformer\n",
    "- This will go into production code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2080, 13)\n",
      "(2080, 13)\n"
     ]
    }
   ],
   "source": [
    "outlier_transformer = Outlier(method='mean')\n",
    "print(train_X.shape)\n",
    "train_X = outlier_transformer.fit_transform(train_X)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>total_post</th>\n",
       "      <th>search_volume</th>\n",
       "      <th>claim_name</th>\n",
       "      <th>D</th>\n",
       "      <th>Private Label</th>\n",
       "      <th>No competition</th>\n",
       "      <th>F</th>\n",
       "      <th>B</th>\n",
       "      <th>H</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>42093.0</td>\n",
       "      <td>low carb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.381675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>140775.0</td>\n",
       "      <td>low carb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.340623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2632.0</td>\n",
       "      <td>105801.0</td>\n",
       "      <td>low carb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.376924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2866.0</td>\n",
       "      <td>117372.0</td>\n",
       "      <td>low carb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.288565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3345.0</td>\n",
       "      <td>105166.0</td>\n",
       "      <td>low carb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.255902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  week  total_post  search_volume claim_name    D  \\\n",
       "0  2016.0    1.0   1.0      1709.0        42093.0   low carb  1.0   \n",
       "1  2016.0    1.0   2.0      1849.0       140775.0   low carb  1.0   \n",
       "2  2016.0    1.0   3.0      2632.0       105801.0   low carb  1.0   \n",
       "3  2016.0    1.0   4.0      2866.0       117372.0   low carb  1.0   \n",
       "4  2016.0    2.0   5.0      3345.0       105166.0   low carb  1.0   \n",
       "\n",
       "   Private Label  No competition    F    B    H  unit_price  \n",
       "0            1.0             0.0  0.0  0.0  0.0    4.381675  \n",
       "1            1.0             0.0  0.0  0.0  0.0    4.340623  \n",
       "2            1.0             0.0  0.0  0.0  0.0    4.376924  \n",
       "3            1.0             0.0  0.0  0.0  0.0    4.288565  \n",
       "4            1.0             0.0  0.0  0.0  0.0    4.255902  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(train_X.shape[0]):\n",
    "    if train_X['month'][i] in [1,2,3]:\n",
    "        train_X.loc[i,'month']='Quarter_1'\n",
    "    elif train_X['month'][i] in [4,5,6]:\n",
    "        train_X.loc[i,'month']='Quarter_2'\n",
    "    elif train_X['month'][i] in [7,8,9]:\n",
    "        train_X.loc[i,'month']='Quarter_3'\n",
    "    else :\n",
    "        train_X.loc[i,'month']='Quarter_4'\n",
    "        \n",
    "        \n",
    "        \n",
    "for i in range(test_X.shape[0]):\n",
    "    if test_X['month'][i] in [1,2,3]:\n",
    "        test_X.loc[i,'month']='Quarter_1'\n",
    "    elif test_X['month'][i] in [4,5,6]:\n",
    "        test_X.loc[i,'month']='Quarter_2'\n",
    "    elif test_X['month'][i] in [7,8,9]:\n",
    "        test_X.loc[i,'month']='Quarter_3'\n",
    "    else :\n",
    "        test_X.loc[i,'month']='Quarter_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_X.shape[0]):\n",
    "    if train_X['month'][i] in [1,12]:\n",
    "        train_X.loc[i,'month']='winter'\n",
    "    elif train_X['month'][i] in [2,3]:\n",
    "        train_X.loc[i,'month']='spring'\n",
    "    elif train_X['month'][i] in [4,5,6]:\n",
    "        train_X.loc[i,'month']='summer'\n",
    "    elif train_X['month'][i] in [7,8,9]:\n",
    "        train_X.loc[i,'month']='mansoon'\n",
    "    else :\n",
    "        train_X.loc[i,'month']='autumn'\n",
    "        \n",
    "        \n",
    "for i in range(test_X.shape[0]):\n",
    "    if test_X['month'][i] in [1,12]:\n",
    "        test_X.loc[i,'month']='winter'\n",
    "    elif test_X['month'][i] in [2,3]:\n",
    "        test_X.loc[i,'month']='spring'\n",
    "    elif test_X['month'][i] in [4,5,6]:\n",
    "        test_X.loc[i,'month']='summer'\n",
    "    elif test_X['month'][i] in [7,8,9]:\n",
    "        test_X.loc[i,'month']='mansoon'\n",
    "    else :\n",
    "        test_X.loc[i,'month']='autumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.drop(columns=['year','week'],axis=1 , inplace=True)\n",
    "test_X.drop(columns=['year','week'],axis=1 , inplace=True)\n",
    "train_X = train_X.rename_column(old_column_name='month',new_column_name='season')\n",
    "test_X = test_X.rename_column(old_column_name='month',new_column_name='season')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_type_1 = pd.get_dummies(train_X['season'], drop_first=True)\n",
    "quarter_type_2 = pd.get_dummies(test_X['season'], drop_first=True)\n",
    "claim_name_1 = pd.get_dummies(train_X['claim_name'], drop_first=True)\n",
    "claim_name_2 = pd.get_dummies(test_X['claim_name'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.concat([train_X, quarter_type_1,claim_name_1] , axis=1)\n",
    "test_X = pd.concat([test_X, quarter_type_2,claim_name_2] , axis=1)\n",
    "train_X.drop(columns=['season','claim_name'], axis=1, inplace=True)\n",
    "test_X.drop(columns=['season','claim_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_post</th>\n",
       "      <th>search_volume</th>\n",
       "      <th>D</th>\n",
       "      <th>Private Label</th>\n",
       "      <th>No competition</th>\n",
       "      <th>F</th>\n",
       "      <th>B</th>\n",
       "      <th>H</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>mansoon</th>\n",
       "      <th>...</th>\n",
       "      <th>highsource of protein</th>\n",
       "      <th>low carb</th>\n",
       "      <th>low sodium</th>\n",
       "      <th>low sugar</th>\n",
       "      <th>no additivespreservatives</th>\n",
       "      <th>poultry</th>\n",
       "      <th>salmon</th>\n",
       "      <th>soy foods</th>\n",
       "      <th>tuna</th>\n",
       "      <th>vegetarian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709.0</td>\n",
       "      <td>42093.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.381675</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1849.0</td>\n",
       "      <td>140775.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.340623</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2632.0</td>\n",
       "      <td>105801.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.376924</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2866.0</td>\n",
       "      <td>117372.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.288565</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>105166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.255902</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>5027.0</td>\n",
       "      <td>160096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.601650</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>5195.0</td>\n",
       "      <td>146546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.031479</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>4524.0</td>\n",
       "      <td>170440.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.630988</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>4554.0</td>\n",
       "      <td>79179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.708822</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>3927.0</td>\n",
       "      <td>68978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.467532</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2080 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_post  search_volume    D  Private Label  No competition    F    B  \\\n",
       "0         1709.0        42093.0  1.0            1.0             0.0  0.0  0.0   \n",
       "1         1849.0       140775.0  1.0            1.0             0.0  0.0  0.0   \n",
       "2         2632.0       105801.0  1.0            1.0             0.0  0.0  0.0   \n",
       "3         2866.0       117372.0  1.0            1.0             0.0  0.0  0.0   \n",
       "4         3345.0       105166.0  1.0            1.0             0.0  0.0  0.0   \n",
       "...          ...            ...  ...            ...             ...  ...  ...   \n",
       "2075      5027.0       160096.0  0.0            0.0             1.0  0.0  0.0   \n",
       "2076      5195.0       146546.0  0.0            0.0             1.0  0.0  0.0   \n",
       "2077      4524.0       170440.0  0.0            0.0             1.0  0.0  0.0   \n",
       "2078      4554.0        79179.0  0.0            0.0             1.0  0.0  0.0   \n",
       "2079      3927.0        68978.0  0.0            0.0             1.0  0.0  0.0   \n",
       "\n",
       "        H  unit_price  mansoon  ...  highsource of protein  low carb  \\\n",
       "0     0.0    4.381675        0  ...                      0         1   \n",
       "1     0.0    4.340623        0  ...                      0         1   \n",
       "2     0.0    4.376924        0  ...                      0         1   \n",
       "3     0.0    4.288565        0  ...                      0         1   \n",
       "4     0.0    4.255902        0  ...                      0         1   \n",
       "...   ...         ...      ...  ...                    ...       ...   \n",
       "2075  0.0   26.601650        0  ...                      0         0   \n",
       "2076  0.0   26.031479        0  ...                      0         0   \n",
       "2077  0.0   26.630988        0  ...                      0         0   \n",
       "2078  0.0   26.708822        0  ...                      0         0   \n",
       "2079  0.0   26.467532        0  ...                      0         0   \n",
       "\n",
       "      low sodium  low sugar  no additivespreservatives  poultry  salmon  \\\n",
       "0              0          0                          0        0       0   \n",
       "1              0          0                          0        0       0   \n",
       "2              0          0                          0        0       0   \n",
       "3              0          0                          0        0       0   \n",
       "4              0          0                          0        0       0   \n",
       "...          ...        ...                        ...      ...     ...   \n",
       "2075           0          0                          0        0       0   \n",
       "2076           0          0                          0        0       0   \n",
       "2077           0          0                          0        0       0   \n",
       "2078           0          0                          0        0       0   \n",
       "2079           0          0                          0        0       0   \n",
       "\n",
       "      soy foods  tuna  vegetarian  \n",
       "0             0     0           0  \n",
       "1             0     0           0  \n",
       "2             0     0           0  \n",
       "3             0     0           0  \n",
       "4             0     0           0  \n",
       "...         ...   ...         ...  \n",
       "2075          0     0           0  \n",
       "2076          0     0           0  \n",
       "2077          0     0           0  \n",
       "2078          0     0           0  \n",
       "2079          0     0           0  \n",
       "\n",
       "[2080 rows x 29 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "sc = PowerTransformer()\n",
    "train_X[['total_post','search_volume','unit_price']] = sc.fit_transform(train_X[['total_post','search_volume','unit_price']])\n",
    "test_X[['total_post','search_volume','unit_price']] = sc.fit_transform(test_X[['total_post','search_volume','unit_price']])\n",
    "train_y = sc.fit_transform(pd.DataFrame(train_y))\n",
    "test_y = sc.fit_transform(pd.DataFrame(test_y))\n",
    "train_y = pd.DataFrame(train_y)\n",
    "test_y = pd.DataFrame(test_y)\n",
    "train_y.rename(columns={0:'sales_dollars_value'}, inplace=True)\n",
    "test_y.rename(columns={0:'sales_dollars_value'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tuna'}"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_X.columns) -set(test_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.drop(columns=['gingerbread','ethical packaging'], axis=1, inplace=True)\n",
    "train_X.drop(columns=['tuna'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9257606590806496"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_rig = LinearRegression()\n",
    "lin_rig.fit(train_X,train_y)\n",
    "y_pred = lin_rig.predict(test_X)\n",
    "y_pred\n",
    "r2_score(test_y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>sales_dollars_value</td> <th>  R-squared:         </th> <td>   0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>         <th>  Adj. R-squared:    </th> <td>   0.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>    <th>  F-statistic:       </th> <td>   5974.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Tue, 30 Aug 2022</td>   <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>12:42:58</td>       <th>  Log-Likelihood:    </th> <td>  1388.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  2080</td>        <th>  AIC:               </th> <td>  -2730.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  2057</td>        <th>  BIC:               </th> <td>  -2601.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    22</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                     <td>   -0.5519</td> <td>    0.013</td> <td>  -41.496</td> <td> 0.000</td> <td>   -0.578</td> <td>   -0.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_post</th>                <td>    0.0287</td> <td>    0.005</td> <td>    5.707</td> <td> 0.000</td> <td>    0.019</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_volume</th>             <td>    0.0528</td> <td>    0.011</td> <td>    5.018</td> <td> 0.000</td> <td>    0.032</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>D</th>                         <td>    0.6392</td> <td>    0.011</td> <td>   59.773</td> <td> 0.000</td> <td>    0.618</td> <td>    0.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Private Label</th>             <td>    0.2810</td> <td>    0.009</td> <td>   31.282</td> <td> 0.000</td> <td>    0.263</td> <td>    0.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No competition</th>            <td>   -1.3927</td> <td>    0.009</td> <td> -148.632</td> <td> 0.000</td> <td>   -1.411</td> <td>   -1.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F</th>                         <td>   -0.1612</td> <td>    0.013</td> <td>  -12.373</td> <td> 0.000</td> <td>   -0.187</td> <td>   -0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>                         <td>    0.0375</td> <td>    0.007</td> <td>    5.400</td> <td> 0.000</td> <td>    0.024</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>H</th>                         <td>   -0.4582</td> <td>    0.010</td> <td>  -44.078</td> <td> 0.000</td> <td>   -0.479</td> <td>   -0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unit_price</th>                <td>    0.0768</td> <td>    0.013</td> <td>    5.779</td> <td> 0.000</td> <td>    0.051</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mansoon</th>                   <td>   -0.0194</td> <td>    0.009</td> <td>   -2.227</td> <td> 0.026</td> <td>   -0.036</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spring</th>                    <td>   -0.0306</td> <td>    0.010</td> <td>   -3.160</td> <td> 0.002</td> <td>   -0.050</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>summer</th>                    <td>   -0.0249</td> <td>    0.009</td> <td>   -2.841</td> <td> 0.005</td> <td>   -0.042</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>winter</th>                    <td>   -0.0187</td> <td>    0.010</td> <td>   -1.936</td> <td> 0.053</td> <td>   -0.038</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blueberry</th>                 <td>    0.5414</td> <td>    0.013</td> <td>   42.469</td> <td> 0.000</td> <td>    0.516</td> <td>    0.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chicken</th>                   <td>   -0.7451</td> <td>    0.013</td> <td>  -58.404</td> <td> 0.000</td> <td>   -0.770</td> <td>   -0.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crab</th>                      <td>   -0.0187</td> <td>    0.013</td> <td>   -1.468</td> <td> 0.142</td> <td>   -0.044</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ethnic & exotic</th>           <td>    2.5991</td> <td>    0.025</td> <td>  104.217</td> <td> 0.000</td> <td>    2.550</td> <td>    2.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>french bisque</th>             <td>   -0.9332</td> <td>    0.012</td> <td>  -74.879</td> <td> 0.000</td> <td>   -0.958</td> <td>   -0.909</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gmo free</th>                  <td>    0.4108</td> <td>    0.017</td> <td>   23.906</td> <td> 0.000</td> <td>    0.377</td> <td>    0.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>highsource of protein</th>     <td>    1.7015</td> <td>    0.025</td> <td>   68.044</td> <td> 0.000</td> <td>    1.652</td> <td>    1.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>low carb</th>                  <td>    1.0257</td> <td>    0.012</td> <td>   86.712</td> <td> 0.000</td> <td>    1.003</td> <td>    1.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>low sodium</th>                <td>    0.1801</td> <td>    0.011</td> <td>   17.007</td> <td> 0.000</td> <td>    0.159</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>low sugar</th>                 <td>    1.3771</td> <td>    0.033</td> <td>   42.145</td> <td> 0.000</td> <td>    1.313</td> <td>    1.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no additivespreservatives</th> <td>    1.2918</td> <td>    0.017</td> <td>   75.109</td> <td> 0.000</td> <td>    1.258</td> <td>    1.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>poultry</th>                   <td>    1.1677</td> <td>    0.028</td> <td>   41.886</td> <td> 0.000</td> <td>    1.113</td> <td>    1.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>salmon</th>                    <td>    3.3864</td> <td>    0.017</td> <td>  195.376</td> <td> 0.000</td> <td>    3.352</td> <td>    3.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>soy foods</th>                 <td>    3.4397</td> <td>    0.027</td> <td>  126.661</td> <td> 0.000</td> <td>    3.386</td> <td>    3.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vegetarian</th>                <td>   -0.9119</td> <td>    0.023</td> <td>  -40.371</td> <td> 0.000</td> <td>   -0.956</td> <td>   -0.868</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>442.916</td> <th>  Durbin-Watson:     </th> <td>   0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2861.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.841</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.494</td>  <th>  Cond. No.          </th> <td>2.12e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.88e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OLS Regression Results                            \n",
       "===============================================================================\n",
       "Dep. Variable:     sales_dollars_value   R-squared:                       0.985\n",
       "Model:                             OLS   Adj. R-squared:                  0.984\n",
       "Method:                  Least Squares   F-statistic:                     5974.\n",
       "Date:                 Tue, 30 Aug 2022   Prob (F-statistic):               0.00\n",
       "Time:                         12:42:58   Log-Likelihood:                 1388.2\n",
       "No. Observations:                 2080   AIC:                            -2730.\n",
       "Df Residuals:                     2057   BIC:                            -2601.\n",
       "Df Model:                           22                                         \n",
       "Covariance Type:             nonrobust                                         \n",
       "=============================================================================================\n",
       "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "const                        -0.5519      0.013    -41.496      0.000      -0.578      -0.526\n",
       "total_post                    0.0287      0.005      5.707      0.000       0.019       0.039\n",
       "search_volume                 0.0528      0.011      5.018      0.000       0.032       0.073\n",
       "D                             0.6392      0.011     59.773      0.000       0.618       0.660\n",
       "Private Label                 0.2810      0.009     31.282      0.000       0.263       0.299\n",
       "No competition               -1.3927      0.009   -148.632      0.000      -1.411      -1.374\n",
       "F                            -0.1612      0.013    -12.373      0.000      -0.187      -0.136\n",
       "B                             0.0375      0.007      5.400      0.000       0.024       0.051\n",
       "H                            -0.4582      0.010    -44.078      0.000      -0.479      -0.438\n",
       "unit_price                    0.0768      0.013      5.779      0.000       0.051       0.103\n",
       "mansoon                      -0.0194      0.009     -2.227      0.026      -0.036      -0.002\n",
       "spring                       -0.0306      0.010     -3.160      0.002      -0.050      -0.012\n",
       "summer                       -0.0249      0.009     -2.841      0.005      -0.042      -0.008\n",
       "winter                       -0.0187      0.010     -1.936      0.053      -0.038       0.000\n",
       "blueberry                     0.5414      0.013     42.469      0.000       0.516       0.566\n",
       "chicken                      -0.7451      0.013    -58.404      0.000      -0.770      -0.720\n",
       "crab                         -0.0187      0.013     -1.468      0.142      -0.044       0.006\n",
       "ethnic & exotic               2.5991      0.025    104.217      0.000       2.550       2.648\n",
       "french bisque                -0.9332      0.012    -74.879      0.000      -0.958      -0.909\n",
       "gmo free                      0.4108      0.017     23.906      0.000       0.377       0.445\n",
       "highsource of protein         1.7015      0.025     68.044      0.000       1.652       1.751\n",
       "low carb                      1.0257      0.012     86.712      0.000       1.003       1.049\n",
       "low sodium                    0.1801      0.011     17.007      0.000       0.159       0.201\n",
       "low sugar                     1.3771      0.033     42.145      0.000       1.313       1.441\n",
       "no additivespreservatives     1.2918      0.017     75.109      0.000       1.258       1.326\n",
       "poultry                       1.1677      0.028     41.886      0.000       1.113       1.222\n",
       "salmon                        3.3864      0.017    195.376      0.000       3.352       3.420\n",
       "soy foods                     3.4397      0.027    126.661      0.000       3.386       3.493\n",
       "vegetarian                   -0.9119      0.023    -40.371      0.000      -0.956      -0.868\n",
       "==============================================================================\n",
       "Omnibus:                      442.916   Durbin-Watson:                   0.268\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2861.101\n",
       "Skew:                          -0.841   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.494   Cond. No.                     2.12e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.88e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = sm.OLS(train_y,sm.add_constant(train_X)).fit()\n",
    "lin_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta_lib.eda.api as eda\n",
    "import ta_lib.core.api as dataset\n",
    "import ta_lib.eda.api as ta_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model\n",
      "--------------------------------------------------\n",
      "Train R2 0.9845893527585499\n",
      "Test R2 0.9283565244096187\n",
      "--------------------------------------------------\n",
      "Train MAPE: 0.17608959392166523\n",
      "Test MAPE: 6.4195608655544705\n",
      "Cross Val Score of MAPE:\n",
      "CV_scores: [2.33993989 1.07941894 1.14089383 1.91901406 2.21494121]\n",
      "Bias : 1.7388415868188265\n",
      "Variance: 0.594313026026358\n"
     ]
    }
   ],
   "source": [
    "def performance(X_train,y_train, X_test,y_test):\n",
    "    lin_reg = sm.OLS(y_train,sm.add_constant(X_train)).fit()\n",
    "    y_train_pred =  lin_reg.predict(sm.add_constant(X_train))\n",
    "    y_test_pred =  lin_reg.predict(sm.add_constant(X_test))\n",
    "    print('Linear Regression Model')\n",
    "    print('-'*50)\n",
    "    print('Train R2',r2_score(y_train,y_train_pred))\n",
    "    print('Test R2',r2_score(y_test,y_test_pred))\n",
    "    print('-'*50)\n",
    "    print('Train MAPE:', mean_absolute_percentage_error(y_train,y_train_pred))\n",
    "    print('Test MAPE:', mean_absolute_percentage_error(y_test,y_test_pred))\n",
    "    print('Cross Val Score of MAPE:')\n",
    "    scores = -1*cross_val_score(LinearRegression(),X_train,y_train,cv=5,\n",
    "                scoring='neg_mean_absolute_percentage_error')\n",
    "    bias  = np.mean(scores)\n",
    "    variance = np.std(scores,ddof=1)\n",
    "    print('CV_scores:',scores)\n",
    "    print('Bias :',bias)\n",
    "    print('Variance:',variance)\n",
    "performance(train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Model\n",
      "--------------------------------------------------\n",
      "Train R2 0.9985742571838314\n",
      "Test R2 0.8877762503203172\n",
      "--------------------------------------------------\n",
      "Train MAPE: 0.033550843164378966\n",
      "Test MAPE: 8.625263381068214\n",
      "Cross Val Score of MAPE:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_scores: [1.58572693 1.20824579 1.54339553 1.41465192 1.4026987 ]\n",
      "Bias : 1.4309437748175688\n",
      "Variance: 0.14769971601007595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def performance(X_train,y_train, X_test,y_test):\n",
    "    rand_for = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "    rand_for.fit(X_train, y_train)\n",
    "    y_train_pred =  rand_for.predict(X_train)\n",
    "    y_test_pred =  rand_for.predict(X_test)\n",
    "    print('Random Forest Regression Model')\n",
    "    print('-'*50)\n",
    "    print('Train R2',r2_score(y_train,y_train_pred))\n",
    "    print('Test R2',r2_score(y_test,y_test_pred))\n",
    "    print('-'*50)\n",
    "    print('Train MAPE:', mean_absolute_percentage_error(y_train,y_train_pred))\n",
    "    print('Test MAPE:', mean_absolute_percentage_error(y_test,y_test_pred))\n",
    "    print('Cross Val Score of MAPE:')\n",
    "    scores = -1*cross_val_score(RandomForestRegressor(),X_train,y_train,cv=5,\n",
    "                scoring='neg_mean_absolute_percentage_error')\n",
    "    bias  = np.mean(scores)\n",
    "    variance = np.std(scores,ddof=1)\n",
    "    print('CV_scores:',scores)\n",
    "    print('Bias :',bias)\n",
    "    print('Variance:',variance)\n",
    "performance(train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8892492284981648"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for = RandomForestRegressor()\n",
    "rand_for.fit(train_X,train_y)\n",
    "y_pred = rand_for.predict(test_X)\n",
    "y_pred\n",
    "r2_score(test_y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_dollars_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.398609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.403922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.404270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.404845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0.862796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>0.832909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>0.838625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.839749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.846790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>634 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sales_dollars_value\n",
       "0               1.398609\n",
       "1               1.404474\n",
       "2               1.403922\n",
       "3               1.404270\n",
       "4               1.404845\n",
       "..                   ...\n",
       "629             0.862796\n",
       "630             0.832909\n",
       "631             0.838625\n",
       "632             0.839749\n",
       "633             0.846790\n",
       "\n",
       "[634 rows x 1 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.rename(columns={0:'sales_dollars_value'}, inplace=True)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = sc.inverse_transform(test_y)\n",
    "y_pred = sc.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(test_y, y_pred)\n",
    "sns.regplot(test_y,y_pred)\n",
    "\n",
    "plt.xlabel('pred_y')\n",
    "plt.ylabel('actual_y')\n",
    "plt.title('actual vs predicted [Random Forest Rergression]')\n",
    "plt.savefig('fig-9.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Model\n",
      "--------------------------------------------------\n",
      "Train R2 1.0\n",
      "Test R2 -0.30841563195483945\n",
      "--------------------------------------------------\n",
      "Train MAPE: 1.7206407025921793e-19\n",
      "Test MAPE: 1.0012047992320248\n",
      "Cross Val Score of MAPE:\n",
      "CV_scores: [1.93585566 3.78685598 1.32393042 1.4248099  1.0867836 ]\n",
      "Bias : 1.9116471128286883\n",
      "Variance: 1.0931394606097138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "def performance(X_train,y_train, X_test,y_test):\n",
    "    des_tree = DecisionTreeRegressor(random_state = 0)\n",
    "    des_tree.fit(X_train, y_train)\n",
    "    y_train_pred =  des_tree.predict(X_train)\n",
    "    y_test_pred =  des_tree.predict(X_test)\n",
    "    print('Random Forest Regression Model')\n",
    "    print('-'*50)\n",
    "    print('Train R2',r2_score(y_train,y_train_pred))\n",
    "    print('Test R2',r2_score(y_test,y_test_pred))\n",
    "    print('-'*50)\n",
    "    print('Train MAPE:', mean_absolute_percentage_error(y_train,y_train_pred))\n",
    "    print('Test MAPE:', mean_absolute_percentage_error(y_test,y_test_pred))\n",
    "    print('Cross Val Score of MAPE:')\n",
    "    scores = -1*cross_val_score(DecisionTreeRegressor(),X_train,y_train,cv=5,\n",
    "                scoring='neg_mean_absolute_percentage_error')\n",
    "    bias  = np.mean(scores)\n",
    "    variance = np.std(scores,ddof=1)\n",
    "    print('CV_scores:',scores)\n",
    "    print('Bias :',bias)\n",
    "    print('Variance:',variance)\n",
    "performance(train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='1433'>\n",
       "  <div class=\"bk-root\" id=\"5cbf3986-92ba-4ce2-a366-316d1d77354d\" data-root-id=\"1433\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"dcda5a82-e7da-48f5-b103-0119ec35d49d\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"GridStack1\",\"overrides\":[],\"properties\":[{\"default\":\"warn\",\"kind\":null,\"name\":\"mode\"},{\"default\":null,\"kind\":null,\"name\":\"ncols\"},{\"default\":null,\"kind\":null,\"name\":\"nrows\"},{\"default\":true,\"kind\":null,\"name\":\"allow_resize\"},{\"default\":true,\"kind\":null,\"name\":\"allow_drag\"},{\"default\":[],\"kind\":null,\"name\":\"state\"}]},{\"extends\":null,\"module\":null,\"name\":\"click1\",\"overrides\":[],\"properties\":[{\"default\":\"\",\"kind\":null,\"name\":\"terminal_output\"},{\"default\":\"\",\"kind\":null,\"name\":\"debug_name\"},{\"default\":0,\"kind\":null,\"name\":\"clears\"}]},{\"extends\":null,\"module\":null,\"name\":\"NotificationAreaBase1\",\"overrides\":[],\"properties\":[{\"default\":\"bottom-right\",\"kind\":null,\"name\":\"position\"},{\"default\":0,\"kind\":null,\"name\":\"_clear\"}]},{\"extends\":null,\"module\":null,\"name\":\"NotificationArea1\",\"overrides\":[],\"properties\":[{\"default\":[],\"kind\":null,\"name\":\"notifications\"},{\"default\":\"bottom-right\",\"kind\":null,\"name\":\"position\"},{\"default\":0,\"kind\":null,\"name\":\"_clear\"},{\"default\":[{\"background\":\"#ffc107\",\"icon\":{\"className\":\"fas fa-exclamation-triangle\",\"color\":\"white\",\"tagName\":\"i\"},\"type\":\"warning\"},{\"background\":\"#007bff\",\"icon\":{\"className\":\"fas fa-info-circle\",\"color\":\"white\",\"tagName\":\"i\"},\"type\":\"info\"}],\"kind\":null,\"name\":\"types\"}]},{\"extends\":null,\"module\":null,\"name\":\"Notification\",\"overrides\":[],\"properties\":[{\"default\":null,\"kind\":null,\"name\":\"background\"},{\"default\":3000,\"kind\":null,\"name\":\"duration\"},{\"default\":null,\"kind\":null,\"name\":\"icon\"},{\"default\":\"\",\"kind\":null,\"name\":\"message\"},{\"default\":null,\"kind\":null,\"name\":\"notification_type\"},{\"default\":false,\"kind\":null,\"name\":\"_destroyed\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"1477\",\"type\":\"AllLabels\"},{\"attributes\":{\"factors\":[\"F\",\"B\",\"french bisque\",\"H\",\"low sugar\",\"vegetarian\",\"gmo free\",\"crab\",\"poultry\",\"highsource of protein\",\"chicken\",\"low sodium\",\"Private Label\",\"unit_price\",\"mansoon\",\"winter\",\"summer\",\"spring\",\"No competition\",\"blueberry\",\"D\",\"search_volume\",\"no additivespreservatives\",\"ethnic & exotic\",\"total_post\",\"soy foods\",\"salmon\",\"low carb\"],\"tags\":[[[\"index\",\"index\",null]]]},\"id\":\"1435\",\"type\":\"FactorRange\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1458\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1467\",\"type\":\"Selection\"},{\"attributes\":{\"source\":{\"id\":\"1466\"}},\"id\":\"1473\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1480\",\"type\":\"AllLabels\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"Feature Correlation with Target Function\",\"text_color\":\"black\",\"text_font_size\":\"12pt\"},\"id\":\"1438\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1476\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis\":{\"id\":\"1450\"},\"coordinates\":null,\"dimension\":1,\"grid_line_color\":null,\"group\":null,\"ticker\":null},\"id\":\"1452\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1444\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"below\":[{\"id\":\"1446\"}],\"center\":[{\"id\":\"1449\"},{\"id\":\"1452\"}],\"height\":300,\"left\":[{\"id\":\"1450\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"renderers\":[{\"id\":\"1472\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"1438\"},\"toolbar\":{\"id\":\"1459\"},\"width\":700,\"x_range\":{\"id\":\"1434\"},\"x_scale\":{\"id\":\"1442\"},\"y_range\":{\"id\":\"1435\"},\"y_scale\":{\"id\":\"1444\"}},\"id\":\"1437\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"child\":{\"id\":\"1437\"},\"name\":\"feature_correlation\",\"title\":\"feature_correlation\"},\"id\":\"1491\",\"type\":\"Panel\"},{\"attributes\":{\"end\":0.4717705577754092,\"reset_end\":0.4717705577754092,\"reset_start\":-0.3577541321462282,\"start\":-0.3577541321462282,\"tags\":[[[\"Pearson_correlation_with_Target\",\"Pearson_correlation_with_Target\",null]]]},\"id\":\"1434\",\"type\":\"Range1d\"},{\"attributes\":{\"callback\":null,\"renderers\":[{\"id\":\"1472\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"index\",\"@{index}\"],[\"Pearson_correlation_with_Target\",\"@{Pearson_correlation_with_Target}\"]]},\"id\":\"1436\",\"type\":\"HoverTool\"},{\"attributes\":{\"fill_color\":{\"value\":\"#30a2da\"},\"hatch_color\":{\"value\":\"#30a2da\"},\"height\":{\"value\":0.8},\"right\":{\"field\":\"Pearson_correlation_with_Target\"},\"y\":{\"field\":\"index\"}},\"id\":\"1469\",\"type\":\"HBar\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#30a2da\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#30a2da\"},\"height\":{\"value\":0.8},\"line_alpha\":{\"value\":0.1},\"right\":{\"field\":\"Pearson_correlation_with_Target\"},\"y\":{\"field\":\"index\"}},\"id\":\"1470\",\"type\":\"HBar\"},{\"attributes\":{\"tools\":[{\"id\":\"1436\"},{\"id\":\"1453\"},{\"id\":\"1454\"},{\"id\":\"1455\"},{\"id\":\"1456\"},{\"id\":\"1457\"}]},\"id\":\"1459\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1455\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1453\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1479\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"axis\":{\"id\":\"1446\"},\"coordinates\":null,\"grid_line_color\":null,\"group\":null,\"ticker\":null},\"id\":\"1449\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1454\",\"type\":\"PanTool\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1466\"},\"glyph\":{\"id\":\"1469\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1471\"},\"nonselection_glyph\":{\"id\":\"1470\"},\"selection_glyph\":{\"id\":\"1474\"},\"view\":{\"id\":\"1473\"}},\"id\":\"1472\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"client_comm_id\":\"6f2063f049d242adacc184ccff40c33f\",\"comm_id\":\"9a4efffa9eef41f8822101cb612fb44b\",\"plot_id\":\"1433\"},\"id\":\"1522\",\"type\":\"panel.models.comm_manager.CommManager\"},{\"attributes\":{\"margin\":[0,0,0,0],\"tabs\":[{\"id\":\"1491\"}]},\"id\":\"1433\",\"type\":\"panel.models.tabs.Tabs\"},{\"attributes\":{\"axis_label\":\"Pearson_correlation_with_Target\",\"coordinates\":null,\"formatter\":{\"id\":\"1476\"},\"group\":null,\"major_label_policy\":{\"id\":\"1477\"},\"ticker\":{\"id\":\"1447\"}},\"id\":\"1446\",\"type\":\"LinearAxis\"},{\"attributes\":{\"axis_label\":\"\",\"coordinates\":null,\"formatter\":{\"id\":\"1479\"},\"group\":null,\"major_label_policy\":{\"id\":\"1480\"},\"ticker\":{\"id\":\"1451\"}},\"id\":\"1450\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"1488\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1451\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"1447\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1442\",\"type\":\"LinearScale\"},{\"attributes\":{\"data\":{\"Pearson_correlation_with_Target\":{\"__ndarray__\":\"fOuXsd140r9Ej1wzr1bQv9AIy+xNQ82/eKdritM2yr9TKHh//kPJv3WzCUNgPse/tMNPDms3w7/OOre4d2jAv8IedKOXw7+/fq4F//bzu7+KNHNyM1y1v7it/DI0L7K/cxY2YPcUo7/AkjxfpKmQv3wyxcy6ame/iCa7FnlyaT/uDzX2sS1rP+hfFb5UmXY/un9gkFErrz/y5VsOeIm7PxZjoT4Rw7w/UDm7kQ/Rwz/M6dx/rdrEP/5X5FztCM8/5P79XZg01T8+dfl0GGTYP04CaUJomtk/+hpqPunE2T8=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[28]},\"index\":[\"F\",\"B\",\"french bisque\",\"H\",\"low sugar\",\"vegetarian\",\"gmo free\",\"crab\",\"poultry\",\"highsource of protein\",\"chicken\",\"low sodium\",\"Private Label\",\"unit_price\",\"mansoon\",\"winter\",\"summer\",\"spring\",\"No competition\",\"blueberry\",\"D\",\"search_volume\",\"no additivespreservatives\",\"ethnic & exotic\",\"total_post\",\"soy foods\",\"salmon\",\"low carb\"]},\"selected\":{\"id\":\"1467\"},\"selection_policy\":{\"id\":\"1488\"}},\"id\":\"1466\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1457\",\"type\":\"ResetTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1458\"}},\"id\":\"1456\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#30a2da\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#30a2da\"},\"height\":{\"value\":0.8},\"line_alpha\":{\"value\":0.2},\"right\":{\"field\":\"Pearson_correlation_with_Target\"},\"y\":{\"field\":\"index\"}},\"id\":\"1471\",\"type\":\"HBar\"},{\"attributes\":{\"fill_alpha\":{\"value\":1.0},\"fill_color\":{\"value\":\"#30a2da\"},\"hatch_alpha\":{\"value\":1.0},\"hatch_color\":{\"value\":\"#30a2da\"},\"hatch_scale\":{\"value\":12.0},\"hatch_weight\":{\"value\":1.0},\"height\":{\"value\":0.8},\"left\":{\"value\":0},\"line_alpha\":{\"value\":1.0},\"line_cap\":{\"value\":\"butt\"},\"line_color\":{\"value\":\"black\"},\"line_dash\":{\"value\":[]},\"line_dash_offset\":{\"value\":0},\"line_join\":{\"value\":\"bevel\"},\"line_width\":{\"value\":1},\"right\":{\"field\":\"Pearson_correlation_with_Target\"},\"y\":{\"field\":\"index\"}},\"id\":\"1474\",\"type\":\"HBar\"}],\"root_ids\":[\"1433\",\"1522\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
       "    var render_items = [{\"docid\":\"dcda5a82-e7da-48f5-b103-0119ec35d49d\",\"root_ids\":[\"1433\"],\"roots\":{\"1433\":\"5cbf3986-92ba-4ce2-a366-316d1d77354d\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Tabs\n",
       "    [0] HoloViews(Bars, name='feature_correlation')"
      ]
     },
     "execution_count": 263,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "1433"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = eda.get_target_correlation(train_X, train_y)\n",
    "display_as_tabs([(k, v) for k,v in out.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total_post', 'search_volume', 'D', 'Private Label', 'No competition', 'F', 'B', 'H', 'unit_price', 'blueberry', 'chicken', 'ethnic & exotic', 'french bisque', 'gmo free', 'highsource of protein', 'low carb', 'low sodium', 'low sugar', 'no additivespreservatives', 'poultry', 'salmon', 'soy foods', 'vegetarian']\n"
     ]
    }
   ],
   "source": [
    "back_ele_features = train_X.columns.tolist()\n",
    "while(len(back_ele_features)>0):\n",
    "    features_with_constant = sm.add_constant(train_X[back_ele_features])\n",
    "    p_values = sm.OLS(train_y, features_with_constant).fit().pvalues[1:]\n",
    "    max_p_value = p_values.max()\n",
    "    if(max_p_value >= 0.05):\n",
    "        excluded_feature = p_values.idxmax()\n",
    "        back_ele_features.remove(excluded_feature)\n",
    "    else:\n",
    "        break \n",
    "print(back_ele_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>sales_dollars_value</td> <th>  R-squared:         </th> <td>   0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>         <th>  Adj. R-squared:    </th> <td>   0.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>    <th>  F-statistic:       </th> <td>   7273.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Tue, 30 Aug 2022</td>   <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>11:50:26</td>       <th>  Log-Likelihood:    </th> <td>  1382.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  2080</td>        <th>  AIC:               </th> <td>  -2727.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  2061</td>        <th>  BIC:               </th> <td>  -2619.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    18</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                     <td>   -0.5707</td> <td>    0.014</td> <td>  -41.523</td> <td> 0.000</td> <td>   -0.598</td> <td>   -0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_post</th>                <td>    0.0272</td> <td>    0.005</td> <td>    5.476</td> <td> 0.000</td> <td>    0.017</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_volume</th>             <td>    0.0549</td> <td>    0.010</td> <td>    5.284</td> <td> 0.000</td> <td>    0.035</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>D</th>                         <td>    0.6463</td> <td>    0.014</td> <td>   45.772</td> <td> 0.000</td> <td>    0.619</td> <td>    0.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Private Label</th>             <td>    0.2727</td> <td>    0.008</td> <td>   35.323</td> <td> 0.000</td> <td>    0.258</td> <td>    0.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No competition</th>            <td>   -1.3949</td> <td>    0.009</td> <td> -151.477</td> <td> 0.000</td> <td>   -1.413</td> <td>   -1.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F</th>                         <td>   -0.1722</td> <td>    0.018</td> <td>   -9.798</td> <td> 0.000</td> <td>   -0.207</td> <td>   -0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>                         <td>    0.0444</td> <td>    0.011</td> <td>    4.026</td> <td> 0.000</td> <td>    0.023</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>H</th>                         <td>   -0.4493</td> <td>    0.013</td> <td>  -34.194</td> <td> 0.000</td> <td>   -0.475</td> <td>   -0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unit_price</th>                <td>    0.0787</td> <td>    0.013</td> <td>    5.919</td> <td> 0.000</td> <td>    0.053</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blueberry</th>                 <td>    0.5459</td> <td>    0.012</td> <td>   44.404</td> <td> 0.000</td> <td>    0.522</td> <td>    0.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chicken</th>                   <td>   -0.7471</td> <td>    0.013</td> <td>  -58.900</td> <td> 0.000</td> <td>   -0.772</td> <td>   -0.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ethnic & exotic</th>           <td>    2.5975</td> <td>    0.025</td> <td>  104.620</td> <td> 0.000</td> <td>    2.549</td> <td>    2.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>french bisque</th>             <td>   -0.9250</td> <td>    0.015</td> <td>  -63.189</td> <td> 0.000</td> <td>   -0.954</td> <td>   -0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gmo free</th>                  <td>    0.4179</td> <td>    0.019</td> <td>   21.988</td> <td> 0.000</td> <td>    0.381</td> <td>    0.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>highsource of protein</th>     <td>    1.7047</td> <td>    0.025</td> <td>   68.412</td> <td> 0.000</td> <td>    1.656</td> <td>    1.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>low carb</th>                  <td>    1.0277</td> <td>    0.012</td> <td>   84.642</td> <td> 0.000</td> <td>    1.004</td> <td>    1.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>low sodium</th>                <td>    0.1699</td> <td>    0.012</td> <td>   14.730</td> <td> 0.000</td> <td>    0.147</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>low sugar</th>                 <td>    1.3801</td> <td>    0.033</td> <td>   42.219</td> <td> 0.000</td> <td>    1.316</td> <td>    1.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no additivespreservatives</th> <td>    1.2908</td> <td>    0.017</td> <td>   75.840</td> <td> 0.000</td> <td>    1.257</td> <td>    1.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>poultry</th>                   <td>    1.1695</td> <td>    0.028</td> <td>   42.168</td> <td> 0.000</td> <td>    1.115</td> <td>    1.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>salmon</th>                    <td>    3.3894</td> <td>    0.017</td> <td>  195.705</td> <td> 0.000</td> <td>    3.355</td> <td>    3.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>soy foods</th>                 <td>    3.4432</td> <td>    0.027</td> <td>  126.795</td> <td> 0.000</td> <td>    3.390</td> <td>    3.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vegetarian</th>                <td>   -0.9092</td> <td>    0.023</td> <td>  -40.293</td> <td> 0.000</td> <td>   -0.953</td> <td>   -0.865</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>450.928</td> <th>  Durbin-Watson:     </th> <td>   0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2921.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.858</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.546</td>  <th>  Cond. No.          </th> <td>3.06e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.04e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OLS Regression Results                            \n",
       "===============================================================================\n",
       "Dep. Variable:     sales_dollars_value   R-squared:                       0.985\n",
       "Model:                             OLS   Adj. R-squared:                  0.984\n",
       "Method:                  Least Squares   F-statistic:                     7273.\n",
       "Date:                 Tue, 30 Aug 2022   Prob (F-statistic):               0.00\n",
       "Time:                         11:50:26   Log-Likelihood:                 1382.3\n",
       "No. Observations:                 2080   AIC:                            -2727.\n",
       "Df Residuals:                     2061   BIC:                            -2619.\n",
       "Df Model:                           18                                         \n",
       "Covariance Type:             nonrobust                                         \n",
       "=============================================================================================\n",
       "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "const                        -0.5707      0.014    -41.523      0.000      -0.598      -0.544\n",
       "total_post                    0.0272      0.005      5.476      0.000       0.017       0.037\n",
       "search_volume                 0.0549      0.010      5.284      0.000       0.035       0.075\n",
       "D                             0.6463      0.014     45.772      0.000       0.619       0.674\n",
       "Private Label                 0.2727      0.008     35.323      0.000       0.258       0.288\n",
       "No competition               -1.3949      0.009   -151.477      0.000      -1.413      -1.377\n",
       "F                            -0.1722      0.018     -9.798      0.000      -0.207      -0.138\n",
       "B                             0.0444      0.011      4.026      0.000       0.023       0.066\n",
       "H                            -0.4493      0.013    -34.194      0.000      -0.475      -0.424\n",
       "unit_price                    0.0787      0.013      5.919      0.000       0.053       0.105\n",
       "blueberry                     0.5459      0.012     44.404      0.000       0.522       0.570\n",
       "chicken                      -0.7471      0.013    -58.900      0.000      -0.772      -0.722\n",
       "ethnic & exotic               2.5975      0.025    104.620      0.000       2.549       2.646\n",
       "french bisque                -0.9250      0.015    -63.189      0.000      -0.954      -0.896\n",
       "gmo free                      0.4179      0.019     21.988      0.000       0.381       0.455\n",
       "highsource of protein         1.7047      0.025     68.412      0.000       1.656       1.754\n",
       "low carb                      1.0277      0.012     84.642      0.000       1.004       1.051\n",
       "low sodium                    0.1699      0.012     14.730      0.000       0.147       0.193\n",
       "low sugar                     1.3801      0.033     42.219      0.000       1.316       1.444\n",
       "no additivespreservatives     1.2908      0.017     75.840      0.000       1.257       1.324\n",
       "poultry                       1.1695      0.028     42.168      0.000       1.115       1.224\n",
       "salmon                        3.3894      0.017    195.705      0.000       3.355       3.423\n",
       "soy foods                     3.4432      0.027    126.795      0.000       3.390       3.496\n",
       "vegetarian                   -0.9092      0.023    -40.293      0.000      -0.953      -0.865\n",
       "==============================================================================\n",
       "Omnibus:                      450.928   Durbin-Watson:                   0.266\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2921.140\n",
       "Skew:                          -0.858   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.546   Cond. No.                     3.06e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.04e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_be = sm.OLS(train_y,sm.add_constant(train_X[back_ele_features])).fit()\n",
    "lin_reg_be.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Model\n",
      "--------------------------------------------------\n",
      "Train R2 0.9984740105165862\n",
      "Test R2 -0.3084156327358307\n",
      "--------------------------------------------------\n",
      "Train MAPE: 0.03807952788596517\n",
      "Test MAPE: 1.0010696592285304\n",
      "Cross Val Score of MAPE:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_scores: [1.53849229 1.12988269 1.56409968 1.46095333 1.38860165]\n",
      "Bias : 1.416405928904013\n",
      "Variance: 0.17433562348698173\n"
     ]
    }
   ],
   "source": [
    "performance(train_X[back_ele_features],train_y,test_X[back_ele_features],test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sample pipelines showcasing how to create column specific pipelines and integrating them overall is presented below\n",
    "\n",
    "- Commonly target encoding is done for categorical variables with too many levels.\n",
    "- We also group sparse levels. For fewer levels one hot encoding/label encoding is preferred.\n",
    "- If there is one dominant level, we can use binary encoding.\n",
    "- This will go into production code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tgt_enc_simple_impt = Pipeline([\n",
    "    ('target_encoding', TargetEncoder(return_df=False)),\n",
    "    ('simple_impute', SimpleImputer(strategy='most_frequent')),\n",
    "])\n",
    "\n",
    "\n",
    "# NOTE: the list of transformations here are not sequential but weighted \n",
    "# (if multiple transforms are specified for a particular column)\n",
    "# for sequential transforms use a pipeline as shown above.\n",
    "features_transformer = ColumnTransformer([\n",
    "    \n",
    "    ## categorical columns\n",
    "    ('tgt_enc', TargetEncoder(return_df=False),\n",
    "     list(set(cat_columns) - set(['technology', 'functional_status', 'platforms']))),\n",
    "    \n",
    "    # NOTE: if the same column gets repeated, then they are weighed in the final output\n",
    "    # If we want a sequence of operations, then we use a pipeline but that doesen't YET support\n",
    "    # get_feature_names. \n",
    "    ('tgt_enc_sim_impt', tgt_enc_simple_impt, ['technology', 'functional_status', 'platforms']),\n",
    "        \n",
    "    ## numeric columns\n",
    "    ('med_enc', SimpleImputer(strategy='median'), num_columns),\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev notes(Encoding):**\n",
    "<details>\n",
    "\n",
    "    Some common practices followed in Categorical Feature Encoding are\n",
    "    * For categorical variables with too many levels, target encoding can be done.\n",
    "    * For fewer levels, one hot encoding can be done.\n",
    "    * If one very dominant level is observed, binary encoding can be used.\n",
    "    \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Feature analysis\n",
    "\n",
    "Using the pipeline above analyze the features and decide on additional features to add/remove from the pipeline. This section will not be part of the production code, unless input data drifts etc. are explicitly demanded in the project.\n",
    "\n",
    "Here we are primarily focused on feature selection/elimination based on business rules, prior knowledge, data analysis.\n",
    "\n",
    "**We are not building any models at this point.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we create some sample data to analyze that we assume represent the population\n",
    "- train the features transformer and do the analysis as below"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_X = train_X.sample(frac=0.1, random_state=context.random_seed)\n",
    "sample_y = train_y.loc[sample_X.index]\n",
    "\n",
    "sample_train_X = get_dataframe(\n",
    "    features_transformer.fit_transform(sample_X, sample_y), \n",
    "    get_feature_names_from_column_transformer(features_transformer)\n",
    ")\n",
    "\n",
    "# nothing to do for target\n",
    "sample_train_y = sample_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the features transformer on the complete data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_X = get_dataframe(\n",
    "    features_transformer.fit_transform(train_X, train_y), \n",
    "    get_feature_names_from_column_transformer(features_transformer)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### 3.2.1 Univariate\n",
    "\n",
    "\n",
    "- Look at each variable independently. This is useful if your models have assumptions on the distribution and/or bounds on the features/target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eda.get_density_plots(train_X, cols=['brand', 'condition'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the plots are html\n",
    "reports.create_report({'univariate': out}, name='feature_analysis_univariate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A report containing the above plot is available [here](https://drive.google.com/file/d/16ntqUc_zvpg0at5pTtO-ljBjw5UVGFnp/view?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the above plots can be generated as a single html as below. The output from this is available [here](https://drive.google.com/file/d/1vUaCcs1PJ4IYo1em9-eZIEj9WuDsnFKT/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.feature_analysis(train_X,'./feature_analysis_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Bivariate - mutual interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find columns with high correlations and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eda.get_correlation_table(train_X)\n",
    "out[out[\"Abs Corr Coef\"] > 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel and source_channel highly correlated. So discarding source_channel\n",
    "# brand and manufacturer are almost same so discarding manufacturer.\n",
    "# Similarly keeping sku between inventory and sku\n",
    "# Similarly keeping condition between conditions and ext_grade\n",
    "# Similarly keeping model_family between platforms, ext_model_family and model_family\n",
    "# Discarding selling price & selling cost as they are multiples of unit price/cost & quantity.\n",
    "# Discarding gp as it is the of selling price and selling cost\n",
    "# order_no, line, invoice_no & customername cannot be IDVs\n",
    "curated_columns = list(\n",
    "    set(train_X.columns.to_list()) \n",
    "    - set(['manufacturer', 'inventory_id', 'ext_grade', 'source_channel',\n",
    "           'tgt_enc_iter_impt_platforms', 'ext_model_family',\n",
    "           'order_no', 'line', 'inventory_id',\n",
    "           'gp', 'selling_price', 'selling_cost','invoice_no','customername'])\n",
    ")\n",
    "\n",
    "train_X = train_X[curated_columns]\n",
    "\n",
    "out = eda.get_correlation_table(train_X)\n",
    "out[out[\"Abs Corr Coef\"] > 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eda.get_bivariate_plots(train_X, x_cols=['brand'], y_cols=['color'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create reports as needed\n",
    "cols = train_X.columns.to_list()\n",
    "all_plots = {}\n",
    "for ii, col1 in enumerate(cols): \n",
    "    for jj in range(ii+1, len(cols)):\n",
    "        col2 = cols[jj]\n",
    "        out = eda.get_bivariate_plots(train_X, x_cols=[col1], y_cols=[col2])\n",
    "        all_plots.update({f'{col2} vs {col1}': out})\n",
    "\n",
    "reports.create_report(all_plots, name='feature_analysis_bivariate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A report containing the bivariate plot is available [here](https://drive.google.com/file/d/1WSGT3586tY-rOmZ57xGILbmL5ll9cSVT/view?usp=sharing)\n",
    "\n",
    "Alternatively, the above plots can be generated as a single html as below. The output from this is available [here](https://drive.google.com/file/d/1A2fz_bjYv8I3iaFDT75JQSDKeJEXxCtp/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.feature_interactions(train_X,'./feature_interaction_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Key Drivers - Interaction with Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eda.get_target_correlation(train_X, train_y)\n",
    "display_as_tabs([(k, v) for k,v in out.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y['unit_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eda.get_feature_importances(train_X, train_y, y_continuous=True)\n",
    "display_as_tabs([(k, v) for k,v in out.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key drivers report like feature importance, bivariate plots can be obtained as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.key_drivers(train_X,train_y, './key_drivers_report.html', y_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev Notes**\n",
    "<details>\n",
    "    \n",
    "- The SHAP plots and bivariate plots in key drivers reports can be obtained by including quick=False as a parameter to key_drivers function call. \n",
    "- SHAP plots and bivariate plots often take long depending on data shape.\n",
    "- The plot with shap is present [here](https://drive.google.com/file/d/1JOTMBLiv3LEqZ-kxZz0RokW9v5UyiGva/view?usp=sharing)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "All the plots like feature analysis, interaction, key drivers can be obtained as a single plot using data exploration method as shown below. The output from this is available [here](https://drive.google.com/file/d/1209MzmSSEhiTYuPfHpaVXFXUVbkaJm0B/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.data_exploration(train_X,train_y,'./data_exploration_report.html', y_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the list of relevant columns\n",
    "save_pipeline(curated_columns, op.abspath(op.join(artifacts_folder, 'curated_columns.joblib')))\n",
    "\n",
    "# save the feature pipeline\n",
    "save_pipeline(features_transformer, op.abspath(op.join(artifacts_folder, 'features.joblib')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Modelling - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Feature Selection(Specific to Regression)\n",
    "\n",
    "- Selecting Features specific to regression\n",
    "- VIF : measure of the amount of multi-collinearity in a set of multiple regressor variables. \n",
    "- On a case to case basis VIF thresholds change. Generally 5 or 10 are acceptable levels.\n",
    "- Usually on a recursive basis when removing the most collinear variable, there can be shuffle in VIF. \n",
    "- Often this section will not be part of the production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train_X.columns)\n",
    "vif = eda.calc_vif(train_X)\n",
    "while max(vif.VIF) > 15:\n",
    "    #removing the largest variable from VIF\n",
    "    cols.remove(vif[(vif.VIF==vif.VIF.max())].variables.tolist()[0])\n",
    "    vif = eda.calc_vif(train_X[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vars = vif.query('VIF < 15').variables\n",
    "reg_vars = list(reg_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transformations like these can be utilised\n",
    "def _custom_data_transform(df, cols2keep=None):\n",
    "    \"\"\"Transformation to drop some columns in the data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        df - pd.DataFrame\n",
    "        cols2keep - columns to keep in the dataframe\n",
    "    \"\"\"\n",
    "    cols2keep = cols2keep or []\n",
    "    if len(cols2keep):\n",
    "        return (df\n",
    "                .select_columns(cols2keep))\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Model training pipeline\n",
    "\n",
    "- Here we focus on creating a collection of pipelines that can be used for training respective models.\n",
    "- Each model pipeline will essentially be of the form\n",
    "```\n",
    "[\n",
    "('preprocessing', preprocessing_pipeline),\n",
    "('feature_selection', feature_selection_pipeline),\n",
    "('estimator', estimator),\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Model Pipeline Build\n",
    "\n",
    "- This will be part of the production code (training only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ppln_ols = Pipeline([\n",
    "    ('',FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':reg_vars})),\n",
    "    ('estimator', SKLStatsmodelOLS())\n",
    "])\n",
    "reg_ppln_ols.fit(train_X, train_y.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ppln_ols['estimator'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 Model Evaluation(Linear Model)\n",
    "\n",
    "This will be part of the production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ppln = Pipeline([\n",
    "    ('', FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':reg_vars})),\n",
    "    ('Linear Regression', SKLStatsmodelOLS())\n",
    "])\n",
    "\n",
    "test_X = get_dataframe(\n",
    "    features_transformer.transform(test_X), \n",
    "    get_feature_names_from_column_transformer(features_transformer)\n",
    ")\n",
    "test_X = test_X[curated_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_linear_report = RegressionReport(model=reg_ppln, x_train=train_X, y_train=train_y, x_test= test_X, y_test= test_y, refit=True)\n",
    "reg_linear_report.get_report(include_shap=False, file_path='regression_linear_model_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev Notes**\n",
    "Use SHAP for variable interpretability.\n",
    "<details>\n",
    "\n",
    "    1. Use SHAP=True to generate variable interpretability plots in the report\n",
    "    2. SHAP is recommended for non parameteric models such as RF, xgboost.\n",
    "    3. However, SHAP reports are time consuming depending on no.of records and model complexity.\n",
    "    \n",
    "A sample of regerssion report with SHAP can be found [here](https://drive.google.com/file/d/18RlQTsT1ze09Cgz-qpb4ha_cvyWbN5F5/view?usp=sharing).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 Residual Analysis\n",
    "- After scoring the model, it is recommended to do a residual analysis to know the distribution of errors\n",
    "- we took a threshold of 30% above which it is marked as over prediction or underprediction\n",
    "- This will not be part of the production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.3\n",
    "residual_analysis = test_X.copy()\n",
    "residual_analysis['prediction'] = reg_ppln_ols.predict(test_X)\n",
    "residual_analysis['actuals'] = test_y.reset_index(drop = True).iloc[:,0].values\n",
    "residual_analysis['forecast_flag'] = 'good'\n",
    "residual_analysis.loc[((residual_analysis['prediction'] > (1+threshold) * residual_analysis['actuals'])\\\n",
    "                       & (residual_analysis['actuals']>100)),'forecast_flag'] = 'over predict'\n",
    "residual_analysis.loc[((residual_analysis['prediction'] < (1-threshold) * residual_analysis['actuals'])\\\n",
    "                       & (residual_analysis['actuals']>100)),'forecast_flag'] = 'under predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_analysis.hvplot.kde(y=\"unit_cost\",by=\"forecast_flag\", ## Grouping by Predictions\n",
    "                                width=800, height=400,\n",
    "                                alpha=0.7,\n",
    "                                ylabel=\"density\",\n",
    "                                xlabel=\"unit_cost\",\n",
    "                                title=f'unit cost(density)',legend='top_right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above plot we can infer that the higher \"over predictions\" are happening for unit_cost > 200.\n",
    "- similarly, the higher \"under predictions\" are happening for unit_cost is zero.\n",
    "\n",
    "This can help us tune the model by a separate model for unit_cost > 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Modelling - XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 Model training pipeline\n",
    "\n",
    "Here we focus on creating a collection of pipelines that can be used for tranining respective models.\n",
    "\n",
    "Each model pipeline will essentially be of the form\n",
    "```\n",
    "[\n",
    "('preprocessing', preprocessing_pipeline),\n",
    "('feature_selection', feature_selection_pipeline),\n",
    "('estimator', estimator),\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Model Pipeline Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find features for some decent defaults\n",
    "estimator = XGBRegressor()\n",
    "xgb_training_pipe_init = Pipeline([\n",
    "    ('XGBoost', XGBRegressor())\n",
    "])\n",
    "xgb_training_pipe_init.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the Feature Importance\n",
    "%matplotlib inline\n",
    "imp = pd.DataFrame({'importance': xgb_training_pipe_init['XGBoost'].feature_importances_})\n",
    "imp.index = train_X.columns\n",
    "imp.sort_values('importance',inplace=True)\n",
    "imp.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'condition','model_family','days_since_last_purchase','first_time_customer','sales_person', are considered to be important and in grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pipeline build based on new importance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find features for some decent defaults\n",
    "imp_features = ['model_family','sku','unit_cost','condition','brand','business_unit']\n",
    "\n",
    "estimator = XGBRegressor()\n",
    "xgb_training_pipe2 = Pipeline([\n",
    "    ('', FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':imp_features})),\n",
    "    ('XGBoost', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search of the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "   'gamma':[0.03],\n",
    "   'min_child_weight':[6],\n",
    "   'learning_rate':[0.1],\n",
    "   'max_depth':[3],\n",
    "   'n_estimators':[500], \n",
    "}\n",
    "est = XGBRegressor()\n",
    "xgb_grid = GridSearchCV(est,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 4,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(train_X, train_y)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Build using the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline_final = Pipeline([\n",
    "    ('', FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':imp_features})),\n",
    "    ('XGBoost', xgb_grid.best_estimator_)\n",
    "])\n",
    "xgb_pipeline_final.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree_report = RegressionReport(model=xgb_pipeline_final, x_train=train_X, y_train=train_y, x_test= test_X, y_test= test_y)\n",
    "reg_tree_report.get_report(include_shap=False, file_path='regression_tree_model_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Regression report containing the feature importances are available [here](https://drive.google.com/file/d/1JBfL3uxPcxBfl0amweXBFmLr7CSHFBUO/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a comparison report of the  linear (vs) tree -based model  approach can be generated as follows.\n",
    "\n",
    "This code will not be part of the production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipelines = [reg_ppln, xgb_pipeline_final]\n",
    "model_comparison_report = RegressionComparison(models=model_pipelines,x=train_X, y=train_y)\n",
    "metrics = model_comparison_report.get_report(file_path='regression_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_report.performance_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A report comparing the performance, metrics between Linear model and Tree model are available [here](https://drive.google.com/file/d/1LDibiFap9K4DKME-Y0S0mtI_05lTdaJF/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev NOTES**\n",
    "<details>\n",
    "\n",
    "the above metrics are absolute nos and not %ges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are choosing LM model for pipelining. General criteria for choosing production models is:\n",
    "\n",
    "- Parametric models (aka whitebox models) such as Linear Regression are easier to explain to non-technical audience.\n",
    "- Generally these are accepted fast and adoption is quicker.\n",
    "- If the downstream calls for optimization using these models parametric models are easier to implement.\n",
    "- When accuracy is primary goal without explainability, the above two takes a backseat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
